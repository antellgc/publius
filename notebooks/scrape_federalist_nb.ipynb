{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('chained_assignment',None)\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape text with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries the main url\n",
    "url = 'https://www.congress.gov/resources/display/content/The+Federalist+Papers'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# parses the text information\n",
    "text_block = soup.find_all(\"div\", class_=\"wiki-content\")[0].get_text()\n",
    "all_texts = []\n",
    "n = 1\n",
    "for string in text_block.split('|| Federalist No.')[1:]:\n",
    "    string = string.replace(u'\\xa0', u' ')\n",
    "    string = '|| Federalist No.' + string\n",
    "    string = string.split('To the People of the State of New York:')[1]\n",
    "    string = string.split('â†‘ Back to Top')[0]\n",
    "    string = string.split('PUBLIUS')[0]\n",
    "    all_texts.append(string)\n",
    "    n += 1\n",
    "\n",
    "# extracts table information\n",
    "count = 0\n",
    "row = []\n",
    "all_rows = []\n",
    "for i in soup.find_all(\"td\", class_=\"confluenceTd\"):\n",
    "    count += 1\n",
    "    if count%5 != 0:\n",
    "        row.append(i.get_text())\n",
    "    else:\n",
    "        row.append(i.get_text())\n",
    "        all_rows.append(row)\n",
    "        row = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store info in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Text</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>General Introduction</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>AFTER an unequivocal experience of the ineffic...</td>\n",
       "      <td>9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Concerning Dangers from Foreign Force and Infl...</td>\n",
       "      <td>Jay</td>\n",
       "      <td>WHEN the people of America reflect that they a...</td>\n",
       "      <td>10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Same Subject Continued: Concerning Dangers...</td>\n",
       "      <td>Jay</td>\n",
       "      <td>IT IS not a new observation that the people of...</td>\n",
       "      <td>8651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Same Subject Continued: Concerning Dangers...</td>\n",
       "      <td>Jay</td>\n",
       "      <td>MY LAST paper assigned several reasons why the...</td>\n",
       "      <td>9621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Same Subject Continued: Concerning Dangers...</td>\n",
       "      <td>Jay</td>\n",
       "      <td>QUEEN ANNE, in her letter of the 1st July, 170...</td>\n",
       "      <td>8176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  No.                                              Title    Author  \\\n",
       "0   1                               General Introduction  Hamilton   \n",
       "1   2  Concerning Dangers from Foreign Force and Infl...       Jay   \n",
       "2   3  The Same Subject Continued: Concerning Dangers...       Jay   \n",
       "3   4  The Same Subject Continued: Concerning Dangers...       Jay   \n",
       "4   5  The Same Subject Continued: Concerning Dangers...       Jay   \n",
       "\n",
       "                                                Text  Length  \n",
       "0  AFTER an unequivocal experience of the ineffic...    9280  \n",
       "1  WHEN the people of America reflect that they a...   10004  \n",
       "2  IT IS not a new observation that the people of...    8651  \n",
       "3  MY LAST paper assigned several reasons why the...    9621  \n",
       "4  QUEEN ANNE, in her letter of the 1st July, 170...    8176  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(all_rows)\n",
    "df.columns = ['No.','Title','Author','Publication','Date']\n",
    "\n",
    "# add text and text length columns\n",
    "df.loc[:,'Text'] = all_texts\n",
    "df = df[['No.','Title','Author','Text']]\n",
    "df.loc[:,'Length'] = df['Text'].apply(len)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n",
    "Many of the Federalist Papers are multi-part installments or continuations of earlier subjects. This could cause problems when it comes to train/test splitting because we want our classifier to identify authorship and not similar thematic content. Accordingly, selected the indices for splitting the datasets that ensure that continuations of the same subject were not assigned to both training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Hamilton': 51, 'Madison': 15, 'Hamilton or Madison': 11, 'Jay': 5, 'Hamilton and Madison': 3})\n",
      "(51, 5) (15, 5) (5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df.Author))\n",
    "\n",
    "# select according to author\n",
    "df_ham = df[df['Author'] == 'Hamilton'].reset_index().drop(['index'], axis=1)\n",
    "df_mad = df[df['Author'] == 'Madison'].reset_index().drop(['index'], axis=1)\n",
    "df_jay = df[df['Author'] == 'Jay'].reset_index().drop(['index'], axis=1)\n",
    "\n",
    "print(df_ham.shape, df_mad.shape, df_jay.shape)\n",
    "\n",
    "# assign first 30 papers from Hamilton to training\n",
    "df_ham_train = df_ham.iloc[:30,:].reset_index().drop(['index'], axis=1)\n",
    "df_ham_test = df_ham.iloc[30:,:].reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# assign first 10 papers from Madison to training\n",
    "df_mad_train = df_mad.iloc[:10,:].reset_index().drop(['index'], axis=1)\n",
    "df_mad_test = df_mad.iloc[10:,:].reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# assign first 3 papers from Madison to training\n",
    "df_jay_train = df_jay.iloc[:4,:].reset_index().drop(['index'], axis=1)\n",
    "df_jay_test = df_jay.iloc[4:,:].reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand dataset into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(df):\n",
    "    all_sentences = []\n",
    "    for t in df['Text']:\n",
    "        sentences = t.split('.')\n",
    "        for s in sentences:\n",
    "            if len(s.strip()) > 10:\n",
    "                all_sentences.append(s.strip())\n",
    "    return all_sentences\n",
    "\n",
    "def expand_df(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    sentences = split_sentence(df)\n",
    "    df_out.loc[:,'sentence'] = sentences\n",
    "    df_out.loc[:,'author'] = df['Author'][0]\n",
    "    return df_out\n",
    "\n",
    "# expand dataframe to sentence-level\n",
    "df_ham_train_passages = expand_df(df_ham_train)\n",
    "df_mad_train_passages = expand_df(df_mad_train)\n",
    "df_jay_train_passages = expand_df(df_jay_train)\n",
    "df_ham_test_passages = expand_df(df_ham_test)\n",
    "df_mad_test_passages = expand_df(df_mad_test)\n",
    "df_jay_test_passages = expand_df(df_jay_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Hamilton': 1597, 'Madison': 787, 'Jay': 145})\n",
      "Counter({'Hamilton': 1384, 'Madison': 326, 'Jay': 55})\n"
     ]
    }
   ],
   "source": [
    "# concatenate into training and testing sets\n",
    "df_train = pd.concat([df_ham_train_passages, df_mad_train_passages, df_jay_train_passages], axis=0)\n",
    "df_test = pd.concat([df_ham_test_passages, df_mad_test_passages, df_jay_test_passages], axis=0)\n",
    "\n",
    "print(Counter(df_train['author']))\n",
    "print(Counter(df_test['author']))\n",
    "\n",
    "df_train.to_csv('../data/train.csv', index=False)\n",
    "df_test.to_csv('../data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Hamilton': 750, 'Madison': 750})\n",
      "Counter({'Hamilton': 300, 'Madison': 300})\n"
     ]
    }
   ],
   "source": [
    "df_ham_train_750 = df_ham_train_passages.sample(n=750, random_state=1).reset_index().drop(['index'], axis=1)\n",
    "df_mad_train_750 = df_mad_train_passages.sample(n=750, random_state=1).reset_index().drop(['index'], axis=1)\n",
    "df_ham_test_300 = df_ham_test_passages.sample(n=300, random_state=1).reset_index().drop(['index'], axis=1)\n",
    "df_mad_test_300 = df_mad_test_passages.sample(n=300, random_state=1).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "df_train_balanced = pd.concat([df_ham_train_750, df_mad_train_750], axis=0)\n",
    "df_test_balanced = pd.concat([df_ham_test_300, df_mad_test_300], axis=0)\n",
    "\n",
    "print(Counter(df_train_balanced['author']))\n",
    "print(Counter(df_test_balanced['author']))\n",
    "\n",
    "df_train_balanced.to_csv('../data/train_balanced.csv', index=False)\n",
    "df_test_balanced.to_csv('../data/test_balanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
